services:
  db:
    image: postgres:15
    container_name: dyno_postgres
    env_file:
      - .env
    volumes:
      - ./db/data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"

  fastapi:
    build: ./app
    container_name: dyno_fastapi
    env_file:
      - .env
    depends_on:
      - db
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
      - ./app/migrations:/app/migrations

  prometheus:
    image: prom/prometheus:latest
    container_name: dyno_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle

  grafana:
    image: grafana/grafana:latest
    container_name: dyno_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards

  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    runtime: nvidia
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - HF_HUB_OFFLINE=1
    volumes:
      - /home/pedro/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8001:8000"  #Use port 8001 when acessing locally to avoid conflict
    command: >
      Qwen/Qwen2.5-7B-Instruct-AWQ
      --quantization awq_marlin
      --gpu-memory-utilization 0.85
      --max-model-len 8192
      --max-num-seqs 8
      --enable-auto-tool-choice
      --tool-call-parser hermes
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]


volumes:
  grafana-storage:
